# -*- coding: utf-8 -*-
"""paddle_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1omAu6CgvnJZn7uiAa9srKmPxQ5eBQSVS

###Dependencies


"""# **OCR with PaddleOCR on photographs**

""""
Overall Goal:

This code performs Optical Character Recognition (OCR) on an image of a whiteboard taken with an iPhone. The image is expected to be in HEIC format. The code will convert it to JPG for compatibility and then use the PaddleOCR library to extract text from the image. The output will be the extracted text and an image with bounding boxes highlighting the detected text. This project is a test of using PaddleOCR for this specific scenario.

Colab Notebook Instructions:


1. **Enable T4 GPU Runtime:**

- Click on "Runtime" in the top menu.
- Select "Change runtime type."
- In the "Hardware accelerator" dropdown, choose "T4 GPU."
- Click "Save."

*Important: Using a T4 GPU is recommended because PaddleOCR can be memory-intensive, especially when loading models. The T4 GPU provides more memory and processing power than the default CPU runtime.*

2. **Upload Your Image:**


- In the left sidebar, click on the "Files" tab (it looks like a folder icon).
- Click on the "Upload to session storage" button (it looks like a file with an up arrow).
- Select the "helloword.heic" image from your computer and upload it.
Copy and Paste Code:"""""

## **Section 1: Install Dependencies**


# --- Install Dependencies ---
# We need to install the necessary libraries for OCR, image processing, and handling HEIC format.
!pip install -q paddlepaddle paddleocr  # PaddlePaddle and PaddleOCR for OCR
!pip install -q opencv-python numpy Pillow  # OpenCV (for image processing), NumPy (for numerical operations), Pillow (for image handling)
!pip install -q matplotlib  # Matplotlib for visualization
!pip install -q pillow-heif  # Library to add HEIC support to Pillow
!cat /proc/cpuinfo | grep "model name"  # Optional: Display CPU information to confirm the runtime environment

"""## **Section 2: Imports**"""

# --- Imports ---
# Import the libraries we just installed.
import paddle
from paddleocr import PaddleOCR, draw_ocr
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import os
import cv2
from pillow_heif import register_heif_opener

"""## **Section 3: Initialize PaddleOCR and Register HEIF Opener**"""

# --- Initialize PaddleOCR and Register HEIF Opener---
# Set up the PaddleOCR engine and register the HEIC opener.

register_heif_opener()  # Enable HEIC support in Pillow

ocr = PaddleOCR(use_angle_cls=True, lang='en')  # Initialize PaddleOCR
# use_angle_cls=True: Enables text angle classification (detects rotated text).
# lang='en': Sets the language to English.

"""## **Section 4: Image Conversion (HEIC to JPG)**"""

# --- Image Conversion (HEIC to JPG) ---
# Convert the HEIC image to JPG for broader compatibility.

image_path = "helloword.heic"  # Path to your uploaded HEIC image
jpg_image_path = "helloword.jpg"  # Path to save the converted JPG image

try:
    image = Image.open(image_path)
    image.convert("RGB").save(jpg_image_path, "jpeg")
    print(f"Image converted successfully to {jpg_image_path}")
except Exception as e:
    print(f"Error during image conversion: {e}")
    exit()

"""## **Section 5: Perform OCR**"""

jpg_image_path = "slide5.jpg"

"""###Preprocessing
Attempting to optimize for a better output using preprocessing techniques such as gray scale image conversion or image enhancement. The contrast variable serves to improve the brightness and the. contrast of the image.  Then, the sharpening filter (unsharp mask) helps bring out edges, so the OCR engine may more readily detect individual characters
"""

from PIL import ImageOps


img = cv2.imread(jpg_image_path)
contrast = cv2.convertScaleAbs(img, alpha=0.5, beta=0.1) # play with alpha

kernel_sharpening = np.array([[0, -1, 0],
[-1, 5, -1],
[0, -1, 0]]) #Apply a simple sharpening filter (unsharp mask)
sharpened = cv2.filter2D(contrast, -1, kernel_sharpening)

cv2.imwrite("sharpened_image.jpg", sharpened)

ocr = PaddleOCR(use_angle_cls=True, lang='en',
det_db_thresh=0.3, det_db_box_thresh=0.5, det_db_unclip_ratio=2.0)

# Perform OCR on the sharpened image
# cls=True: Enables character-level classification (improves accuracy).
result = ocr.ocr("sharpened_image.jpg", cls=True)

"""## **Section 6: Visualization**"""

# Open the ORIGINAL Image (Not Preprocessed)
image = Image.open(jpg_image_path).convert('RGB')

# Extract OCR Results
boxes = [line[0] for line in result[0]]  # Coordinates of bounding boxes
txts = [line[1][0] for line in result[0]]  # Extracted text
scores = [line[1][1] for line in result[0]]  # Confidence scores

# Draw OCR Results on the Original Image
im_show = draw_ocr(
    np.array(image),  # Pass original RGB image here
    boxes,
    txts,
    scores,
    font_path='/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf'
)

# Convert back to PIL for saving
im_show = Image.fromarray(im_show)

# Save the Visualization with Bounding Boxes
im_show.save('result.jpg')

# Display the Image with OCR Results
plt.figure(figsize=(15, 15))
plt.imshow(im_show)
plt.title('OCR Result')
plt.axis('off')
plt.show()

"""## **Section 7: Print OCR Result**"""

# --- Print OCR Result ---
# Print the extracted text to the console.

print("--- OCR Result ---")
for line in result[0]:
    print(line[1][0])

print(result)